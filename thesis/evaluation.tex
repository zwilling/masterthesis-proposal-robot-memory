\chapter{Evaluation}
\label{sec:evaluation}
This chapter presents the evaluation results of the thesis. After some
remarks about the evaluation context in \refsec{sec:eval-context}, we
analyze the durations of different robot memory operations in
\refsec{sec:op-durations}. This includes comparing the durations for
different expressiveness levels and database sizes to find a
compromise between expressiveness and performance. Furthermore, we
analyze the overhead of database operations introduced by robot memory
features. In \refsec{sec:performance} we present the performance of
the system in the already introduced application scenarios. This
includes CPU and memory usage, network throughput, and statistics
about robot memory operations. Qualitatively, we evaluate how well the
features of the robot memory work, how it can support the development
of application scenarios, and where limitations are. Furthermore, we
present experiments regarding the compromise of expressiveness and
performance. \todo[inline]{review mentioning of all sections}

\section{Evaluation context}
\label{sec:eval-context}
The benchmarks presented in this chapter were performed on Fedora 23
systems with 16 GB RAM and an Intel Core i7-3770 with eight cores at
$3.4$~Ghz. For local benchmarks everything, including Fawkes, Mongodb,
the Gazebo simulation and ROS, ran on a single system. For distributed
benchmarks, three identical systems were used. Each system hosted its
own Fawkes, ROS, and Mongodb processes and one system additionally,
hosts the Gazebo simulation.

Since the robot memory runs inside the Fawkes framework and thus
inside the Fawkes process, the performance of the robot memory can not
directly be measured separately and is influenced by Fawkes. The
influences are caused by other components, such as localization,
reasoning, and collision avoidance, and by the thread management of
Fawkes. To softly guarantee loop times for other threads, Fawkes
suspends threads with a too long loop iteration. When measureing
durations of robot memory operations, this can increase large
measurement values because if an operation takes longer than the
allowed loop iteration time, the time being suspended is added to the
measurement.

\section{Robot Memory Operations}
\label{sec:op-durations}
In this section, we analyze the run-time durations of robot memory
operations, such as insert, query, and update. We also analyze how
these change with computables and triggers. The goal is to find out
how fast the robot memory works. Besides the influence of the
implementation, the durations heavily depend on the underlying
complexity (e.g. of a query) and \emph{domain size}, which is the
amount of information stored in the robot memory. Here, we want to
find out how the durations scale with increasing domain size and
increasing complexity.

The structure of the data used for this evaluation is chosen in a way
that it is similar to information that is usually stored in a robot
memory and that it also simplifies the analysis. The used data mimics
a robot's knowledge about object and their positions to solve a tidy
up scenario. For each object, the robot memory contains a document
with the object's name, current position, and the storage position it
belongs to. Names are unique and storage positions are randomly chosen
out of $1000$ possibilities. Objects are currently placed at their
storage position with probability $0.01$ and random otherwise. The
object's name is string to enforce string comparisons, which are
expected to be often needed in a real scenario. For evaluation
reasons, we do not index the collection by the s name right now
because this heavily impacts the duration. An evaluation plugin in
Fawkes generates the data and calls random operations. To analyze how
the durations scale with the domain size, the plugin calls the
operations repeatedly after increasing the domain size from $0$ to
$100000$ documents by steps of $1000$ documents.

The analysis is separated into the main classes of operations, namely
insertions in \refsec{sec:insertions}, queries in
\refsec{sec:queries}, and updates in \refsec{sec:updates}. Because
deletions behave very similar to updates, both search for documents
and work with them, they are also covered in the section about
updates. \refsec{sec:eval-computables} covers and explains the impact
of computables on query durations and \refsec{sec:eval-trigger} deals
with the impact of event triggers. Operations that are performed
rarely are not analyzed. For example dropping or restoring a collection and
registration of triggers and computables are only performed once
during initialization.  In the course of implementing and evaluating
the application scenarios, their durations were not noticible compared
to the initialization time of the whole robot software.

\subsection{Insertions}
\label{sec:insertions}
\begin{figure}
  \centering
  \begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth]{plots/insert-durations}
    \caption{Insertions}
    \label{fig:insert-durations}
  \end{subfigure}
  \begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth]{plots/query-durations}
    \caption{Queries}
    \label{fig:query-durations}
  \end{subfigure}
  \caption[Duration of robot memory operations with increasing domain size]{Duration of robot memory operations with increasing domain size}
  \label{fig:eval-durations-1}
\end{figure}
The insertion of a new document into the robot memory is overall the
fastest operation compared to queries and
updates. \reffig{fig:insert-durations} shows the distribution of
insert durations with increasing domain size. It is noticible that the
duration does not depend on the domain size and thus has run-time
complexity of $O(1)$. The insertion time is small with an average of
$0.125ms$. However, there are single outliers not present in
\reffig{fig:insert-durations}. These outliers occur periodicly, when
MongoDB flushes database changes from the RAM to the hard drive. We
could reduce frequency of these outliers to one in $60s$, which is the
default flushing frequency of MongoDB. To reach this, we had to
disable the forward logging of MongoDB, called Journaling. In this
evaluation scenario, the outliers took about $0.3s$ because of the
large amount of written documents and the threading in Fawkes.  The
overhead of the robot memory compared to the duration of the raw
MongoDB operation has an average of $0.006ms$, which is about $5.5\%$.
The overhead is caused by verifying the collection name, deciding if
the local or distributed database is used, adding meta-data, and
mutual exclusion of database usage. The robot memory overhead mesured
here does not include checking if triggers were activated by inserting
the document. This is caused by the asynchron and seperate checking by
the trigger manager. The size and the complexity of insertes
documnents did not make a noticable difference.\todo{nedd to add
  numbers?}

\subsection{Queries}
\label{sec:queries}
Queries are more complex operations than insertions and also take more
time. \reffig{fig:query-durations} shows that query durations heavily
depends on many factors, such as domain-size and query complexity. The
query durations, when searching for an object by it's unique name,
lineary depend on the domain size. The other plot shows the query
durations for finding objects that are not at their storage location
and thus would have to be tidyied up. The query is more complex
because it contains a comparison between two values that is formulated
in JavaScript. From $0$ to about $10000$ documents, also a linear
increase can be seen. With more documents the average duration does
not increase, because of a query evaluation trick of MongoDB. MongoDB
lazily evaluates queries and returns a cursor to the first batch of
documents that match the query. While the user iteratively fetches
documents from the cursor, MongoDB continues the query evaluation if
the batch was emptied. For the 'find object name' query, the whole
database was searched because the unique object could not fill the
batch. However it is possible to request a smaller batch (e.g. only
one) document for faster computation.  \todo[inline]{comparison with
  indexing} The overhead of the robot memory query operation does not
depend on the domain size and has an average duration of $0.6ms$. The
largest part of that overhead is caused by the computable manager,
even if in this scenario no computables are registered. The computable
manager performs a single insert and remove on a seperate collection
to prepare checking if the query matches a computable and to clean up
afterwards. Because of this insertion, the duration spikes observed
for insertions can also occur for queries.  \todo[inline]{more
  different query complexities?}  As \reffig{fig:query-durations}
shows, the query duration heavily depends on the complexity of the
query. Especially the expressive JavaScript functions are expensive
compared to the MongoDB internal query language without JavaScript. By
formulating queries smartly, complex questions can often be
efficiently in practise. For example checking wheather the dishwasher
is full sounds like a question that is computationally costly because
it requires JavaScript function. But it can be formulated efficiently
by first filtering only the objects in the dishwasher with a fast
JavaScript-free query and then summing up the objects volume to check
if it exceeds a given threashold. This way the costly sum computation,
which can be done by aggregation or JavaScript, only needs to be
computed for the few objects in the dishwasher.
  \todo[inline]{concrete example for query formulation?}
  \todo[inline]{aggregation/map-reduce graph?}

\subsection{Updates and Deletions}
\label{sec:updates}
\begin{figure}
  \centering
  \begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth]{plots/update-durations}
    \caption{Updates}
    \label{fig:update-durations}
  \end{subfigure}
  \begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth]{plots/computable-durations}
    \caption{Computables}
    \label{fig:computable-durations}
  \end{subfigure}
  \caption[Duration of robot memory operations with increasing domain size]{Duration of robot memory operations with increasing domain size}
  \label{fig:eval-durations-2}
\end{figure}
Updates consist of a query defining what should be updated and some
key-value pairs, which should be changed. Thus the duration of an
update should be similar to an update plus an
insertion. \reffig{fig:update-durations} shows the duration of
position updates of objects with a random name. Because the used
update operation only updates a single document, the durations are
roughly uniformly distributed with an upper bound matching the
duration of 'find object' queries in
\reffig{fig:query-durations}. Thus the duration of update operations
also scale linearly with the domain size. Duration of queries
searching for only one document also behave as in
\reffig{fig:update-durations}.  Because delete operations also consist
of a query and a fast change operation, they behave similar to
updates. The difference is that by default deletions are executed on
all documents and updates only on a single one. For both deletions and
updates the overhead does not depend on the database size. Both
updates and deletions have an average overhead duration below
$0.02ms$. In contrast to to query operations, the computable manager
is not involved, because computed documents should not be updated and
they do not need to be removed manualy.

\subsection{Computables}
\label{sec:eval-computables}
overhead
performance-size-expressiveness
scale liniar/quadratic with size
computable insert, x*query, remove (insert+ remove once, query -x)
\subsection{Trigger}
\label{sec:eval-trigger}
overhead
performance-size-expressiveness
scale liniar/quadratic with size


\section{Performance in evaluation scenarios}
\label{sec:performance}

data scenario: arm, rcll

\section{Qualitative Evaluation}
\todo[inline]{refine qualitative structure}