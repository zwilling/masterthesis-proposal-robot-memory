\chapter{Implementation}
\label{sec:impl}
In the previous chapter, we presented the approach of the thesis and
the architecture of the robot memory. On this basis, we present
implementation considerations in this chapter. The implementation of
the robot memory is separated according to the layered
architecture. \refsec{sec:back-end} presents the implementation of the
back-end containing the MongoDB databases and \refsec{sec:impl-memory}
presents the implementation of the robot memory with the operations-,
trigger-, and computable manager. Both application layers are covered
in \refsec{sec:impl-planner}. We conclude with the description of the
evaluation scenarios and how they were implemented in
\refsec{sec:applicationscenarios}.

\section{MongoDB Back-End}
\label{sec:back-end}
The back-end of the robot memory is based on MongoDB databases. It
acts as storage of the robot memory and executes insert, query,
update, and delete operations. The representation of stored information
utilizes the document structure of MongoDB with key-value pairs and
nested sub-documents. This allows a very flexible storage of
information-pieces in the structure that is induced by the application
and can be expanded by meta information from the robot memory.

\begin{wrapfigure}{r}{0.47\textwidth}
  \vspace{-0.8cm}
\begin{lstlisting}[style=SmallJSON,
  caption={Representation of a knowledge piece in the back-end},
  label=lst:backend,
  framexleftmargin=1pt, xleftmargin=0pt,
 morekeywords={}, numbers=none]
 {
   _robot_memory_info:
   {
     persistent: true,
     decay_time: ISODate(
       "2016-05-19T 23:50:00.000Z")
   },
   type: "object info",
   name: "milk_1",
   position: {x:2.5, y:1.0, z:0.0},
   storage_place: "refrigerator"
 }
\end{lstlisting}
\vspace{-8mm}
\end{wrapfigure}
An example document stored in the back-end is shown in
\reflst{lst:backend}. It contains knowledge about a bottle of milk as
it could be needed by a planner with additional information where it
should be stored later. Additionally the document contains meta
information needed by the robot memory (e.g. if the document should be
stored persistently or removed at restart and when it should be
dropped because its use-time has expired). How these documents are
parsed, serialized, stored, and queried again is handled by
MongoDB. To connect to MongoDB from the robot memory, we use the
\texttt{mongodb} plugin in Fawkes. It was developed for the
implementation of the Generic Robot Database~\cite{RoboDB} and
utilizes the C++ driver of MongoDB. We also extended this plugin,
e.g. to properly connect to a distributed replica set.

As the architecture in \reffig{fig:arch} shows, the MongoDB backend
contains a local and a shared part. Each part is operated by a
separate \texttt{mongod} instance, which is the daemon process of the
MongoDB system. It manages data access, handles data requests, and
performs background management operations. Each \texttt{mongod}
instance is accessable over its unique port and can contain multiple
databases. The databases of the robot memory that are only locally
relevant are managed by the logal \texttt{mongod} instance. The shared
\texttt{mongod} instance manages the distribution of shared databases
in a multi-robot system. Thus we configured it to be part of replica
set as already described in \refsec{sec:mongodb}. This ensures the
efficient distribution of the databases and handles important
distribution issues, such as Primary election, consistency, and
synchronization.  \todo[inline]{explain why no sharding is used?}  The
robot memory needs multiple connections to both \texttt{mongod}
instances because single connections, as provided by the C++ driver,
are not thread safe\todo{explain thread safe?}. Thus we use the connection manager of the
\texttt{mongodb} Fawkes plugin to create two connections for usual
operations, computables, and triggers.
%
The MongoDB back-end also contains the operations log (oplog), a
separate capped collection containing the list of changes to the
database with a timestamp. The oplog is accessed by the robot memory
to analyze database changes for triggers. However, the oplog is only
created for replicated database, because its original purpose is
logging changes to propagate them to other instances in the Replica
Set. Thus we also have to configure the local \texttt{mongod} instance
as Replica Set, but this set only contains itself because its
databases are only locally relevant.

Because the robot memory requires a special configuration of the
MongoDB deamons, we also implemented an automated setup of the
back-end. This setup starts the \texttt{mongod} processes as
subprocesses of Fawkes if they are not already running. Each process
needs to be configured, most importantly, with the Replica Set name,
the database path, where the databases are persistently stored on the
hard-drive, and the oplog size. After the startup, the \texttt{mongod}
instances need to be initialized, when they are started for the first
time. Thus the automated setup sends commands for initialization of
the Relica Set with information about the members of the
set. Furthermore, commands for the query evaluation are send, to allow
query evaluation on Secondaries.  \todo[inline]{Mention ignoring error
  code when already initialized?}  When Fawkes is exited, also the
MongoDB subprocesses are finalized again.

\section{Robot Memory}
\label{sec:impl-memory}
The robot memory middle-layer implements most functions of the robot
memory that exceed a typical database. Because this is a central and
large part of this thesis, we split the implementation into the query
language in \refsec{sec:impl-query-language}, the operation manager in
\refsec{sec:impl-opmanager}, computables in
\refsec{sec:impl-computables}, triggers in \refsec{sec:impl-triggers},
and unit-tests in \refsec{sec:impl-unittests}. The robot memory layer
can be accessed in Fawkes through the \texttt{RobotMemoryAspect} and
through sending messages to the blackboard interface of the robot
memory. Both the aspect and the interface are provided by the
\texttt{robot-memory} plugin.

\subsection{Query Language}
\label{sec:impl-query-language}
A central question is which query language should be used between
applications and the robot memory because this determines the
expressiveness and has a large impact on the performance. We choose to
use the query language of MongoDB as it is already used between the
robot memory and the back-end. This has many advantages compared to
using other query languages, such as SQL, SPARQL,
XQuery~\cite{query-languages}, and JSONiq~\cite{jsoniq}.  For the
applications using the robot memory, the query language of MongoDB is
a good choice because it is an intuitive query language and has been
proven as efficient for usual and well designed queries. It is also
highly expressive when using additional JavaScript functions or the
MapReduce paradigm~\cite{mongodb,RoboDB}. For the robot memory, it
requires no translation before applying queries to the
database. Furthermore it allows extending and modifying queries
because queries are structured as documents with key-value fields and
can be nested or executed in sequence. Another advantage of the
MongoDB query language is that it can easily be parsed (e.g. from a
string) by using the MongoDB C++ driver. The resulting object can be
analyzed and modified for example to add key-value pairs or to check
if computables are queried.

\subsection{Operation Manager}
\label{sec:impl-opmanager}
The MongoDB query language provides the basis for the operation
manager, which receives insert, query, update, and deletion
requests. Received requests are analysed using the MongoDB C++ driver
and modified before being applied to the back-end. This way, the
operation manager can add meta information of the robot memory to
documents and queries, and the computable manager can ground its
decision if computables need to be executed on the contents of a
query.

The basic operations on the robot memory are insertions, queries,
updates, and deletions. For all four, the operation specifies on which
collection in which database the operation should be performed. The
collection string contains both separated by a dot
(e.g. \texttt{'robmem.worldmodel'} for the worldmodel collection in
the robmem database). \todo{mention default value collection?}  Using
the configurable list of shared databases, the collection string also
specifies whether the operation should be performed on the local or
shared \texttt{mongod} instance. Because the connections to MongoDB
are not thread safe, the implementation of all operations guarantees
mutual exclusion of connection usage. Furthermore, the operation
manager handles exceptions caused by operations, e.g. when a query can
not be parsed or an object contains invalid fields.

An \textbf{insertion} operation also specifies the document that
should be inserted. Before performing the insertion on the database,
the operation manager can add meta information of the robot memory,
for example the insertion time if the collection is configured to be a
short time memory. The meta information is contained in a sub-document
under the \texttt{\_robmem\_info} key.

For \textbf{queries}, the operation also specifies the query
itself. The operation manager analyzes the query and modifies similar
to how it modifies documents. It adds a filter and a read
preference. The filter hides meta information of the robot memory from
the application. The read preference specifies that the query should
be executed closest available of a replica set. This should always be
the local one because it has the lowest ping time and thus leads to a
faster query times than performing queries on remote replica set
members. Furthermore the query is passed to the computation manager to
check if a computable has to be executed.

\textbf{Update} operations contain a query specifying which documents
should be updated and a document containing the changes that should be
applied. By default the first matching documents in the specified
collection is replaced by the update document. It is possible to
modify this behavior with additional options. There are options for
perform the update on all matching documents and for inserting the
document even if no document in the collection matches the query
(called \emph{upsert}). To keep key-value pairs in the original
document, the update document needs to contain updated values a
\texttt{\$set} sub-document.\todo{listing for \$set?} In contrast to
query operations, updates do not lead to the execution of computables,
because it is pointless to update them because of the short lifetime.

\textbf{Deletion} operations have an attached query specifying which
documents should be removed. The operation manager does not need to
perform special modifications of this query.

Additionally to these basic operations, the operation manager can also
export the contents of a collection to a file (called \emph{dump}). It
can also import a collection from a file in an operation called
\emph{restore}. These operations can be used to sava and load a world
model that is contained in a collection. For example in the RCLL, this
allows setting the world model in a prepared state to test the
behavior of the agent in that state. The dump and restore operations
are implemented by calling the \texttt{mongodump} and
\texttt{mongorestore} command line tools of MongoDB with appropriate
parameters.

\subsection{Computables}
\label{sec:impl-computables}
Computables allow the computation of documents on demand, that is when
a query operation asks for a document that can be provided by the
computable. The computable manager is the entity used for registering
and unregistering computables as well as for checking which
computables should be executed for a query.\\
\begin{listing}
\refstepcounter{listing}
\addtocounter{lstlisting}{1}
\noindent
\begin{minipage}[b]{.30\textwidth}
\begin{lstlisting}[style=SmallJSON,
  %caption={Computable Query},
  %label=lst:comp-def,
  framexleftmargin=5pt, xleftmargin=0pt,
 morekeywords={}, numbers=none]
{
  compute: "sum",
  x: {$exists:true},
  y: {$exists:true}
}
\end{lstlisting}
\captionof{sublisting}{Computable query defining what is computed}
\end{minipage}%
\hfill
\begin{minipage}[b]{.25\textwidth}
\begin{lstlisting}[style=SmallJSON,
  %caption={Query requirering computable},
  %label=lst:comp-query,
  framexleftmargin=5pt, xleftmargin=0pt,
 morekeywords={}, numbers=none]
{
  compute: "sum",
  x: 15,
  y: 4
}
\end{lstlisting}
\captionof{sublisting}{Query requireing the computable}
\end{minipage}%
\hfill
\begin{minipage}[b]{.25\textwidth}
\begin{lstlisting}[style=SmallJSON,
  %caption={Computed document},
  %label=lst:comp-res,
  framexleftmargin=5pt, xleftmargin=0pt,
 morekeywords={}, numbers=none]
{
  compute: "sum",
  x: 15,
  y: 4,
  sum: 19
}
\end{lstlisting}
  \vspace{-0.3cm}
\captionof{sublisting}{Resulting document}
  \vspace{0.3cm}
\end{minipage}%
\caption{Queries and documents involved in a computable for addition}
\label{lst:comp}
\end{listing}

\begin{wrapfigure}{r}{0.49\textwidth}
  \vspace{-0.8cm}
\begin{lstlisting}[style=SmallCpp,
  caption={Function of a computable},
  label=lst:comp-func,
  framexleftmargin=5pt, xleftmargin=0pt,
 morekeywords={}, numbers=none]
std::list<mongo::BSONObj>
compute_sum(mongo::BSONObj query,
            std::string collection)
{
  std::list<mongo::BSONObj> result;
  int x = query.getField("x").Int();
  int y = query.getField("y").Int();
  mongo::BSONObjBuilder b;
  b << "compute" << "sum"
    << "x" << x << "y" << y
    << "sum" << x + y;
  result.push_back(b.obj());
  return result;
}
\end{lstlisting}
\vspace{-8mm}
\end{wrapfigure}

\reflst{lst:comp} and \reflst{lst:comp-func} show how queries,
documents, and functions are involved in a computable on the example
of an addition computable. When some component registers a computable
on a collection, it needs to give a reference to the function
performing the actual computation and a definition which documents can
be provided by the computable. This definition is specified as
\emph{computable query}, as shown in \reflst{lst:comp}a. Whenever the
robot memory has to answer a query (e.g. \reflst{lst:comp}b) that is
matched by the computable query, the computable is executed. The
referenced function for the addition computable is shown in
\reflst{lst:comp-func} and yields a list of computed documents that,
in this example, only contains the result shown in \reflst{lst:comp}c.

The computable manager checks whether queries passed to it can be
answered by registered computables. To check if the robot memory query
is matched by a computable query, the robot memory query is inserted
as document in a separate and empty collection. When this inserted
document is returned by performing the computable query on the
collection, the function of the computable is called. This function
(\reflst{lst:comp-func}) takes the query causing the computation
(\reflst{lst:comp}b) and the collection as parameters. Thus it can use
values in the query (\texttt{x} and \texttt{y}) to determine what
should be computed. The function then computes a list of resulting
documents (list containing \reflst{lst:comp}c) and returns it to the
computable manager. By defining the computable query appropriately
(e.g. with \texttt{\$exists}), is is ensured that all values required
by the function are provided by the query. It is also possible to
ommit required values intentionally. For example the computable for
blackboard interfaces in Fawkes, checks if an interface id is givien,
and then eigther returns a document for the single interface with the
id or all interfaces matching the interface type.

After a computable returned the list of computed documents, the
computable manager inserts these documents in the specified collection
of the robot memory. Finally, the operation manager evaluates the
original query as usual on the collection. The query can return computed
documents as well as persistently stored documents. Thus the computed
information is embedded in the already existing information. Another
advantage of evaluating the original query on the collection, is that
the query can have more key-value fields than required by the
computable, for example to filter computed documents or add
aggregation functions.

To lower the computational effort of computables, we implemented
caching of computed documents. Whenever a query is identical to a
query that caused computation in the caching time before, the no
computables are executed for it. Computed documents remain in the
robot memory during this caching time. This is implemented by adding
the expiration time of computed documents to their meta information
and periodically removing documents with passed wxpiration time.

Computables can depend on the current content of the robot memory, by
using the robot memory themself in their function. This can be used
for hybrid reasoning by transform documents already contained in the
robot memory into other representations. To allow computables to
depend on the result of other computables, there is a
prioritization. The computable manager uses this prioritization to
determine the order in which computable checked.

The \texttt{robot-memory} plugin in Fawkes provides two basic
computables. One provides access to the blackboard by computing
documents containing the fields of blackboard interfaces with matching
types and ids. The other transforms documents describing 3D positions
into other frames by using the transform aspect of Fawkes. All other
computables have to be provided by other plugins.

\subsection{Triggers}
\label{sec:impl-triggers}
Triggers notify components about changes in the database, for example
to keep a reasoner intern world model up to date. To register a triger
at the trigger manager, the component has to provide the name of the
collection that should be observed, a reference to a callback
function, and a query defining the event in which the callback
function should be called. An example query used for being notified
about new or modified orders in the RCLL is \texttt{\{relation:
  "order"\}}. This query is used to search the oplog for changes. The
oplog is a capped collection in MongoDB, which logs all changes to
propagate them in a Replica Set.
\begin{wrapfigure}{r}{0.42\textwidth}
  \vspace{-0.8cm}
\begin{lstlisting}[style=SmallJSON,
  caption={Document in the oplog},
  label=lst:oplog,
  framexleftmargin=2pt, xleftmargin=0pt,
 morekeywords={}, numbers=none]
{
  ns: "syncedrobmem.clipswm",
  ts: Timestamp(1485369072, 5),
  op: "i",
  o: {
    _id : ObjectId("58c14a14"),
    relation: "order",
    id: 2,
    complexity: "C0",
    delivery-gate: 3,
    quantity-requested: 1,
    quantity-delivered: 0,
    begin: 209,
    end: 282 }
}
\end{lstlisting}
\vspace{-8mm}
\end{wrapfigure}
\reflst{lst:oplog} shows an example document contained in the
oplog. Besides the collaction name and timestamp of the change, it
shows the type the causing operation (\texttt{op:"i"} stands for
insertion) and the inserted, updated, or removed document as
sub-document under the \texttt{o} key. For each new trigger, the
trigger manager creates a cursor on oplog in MongoDB with the trigger
query. Initially this cursor points to the end of the oplog (position
3 in \reffig{fig:oplog-cursor}). Because the oplog is a capped
collection, new changes (e.g. 4 and 5 in \reffig{fig:oplog-cursor})
are appended behind the position the cursor points to. During the main
loop of Fawkes, the trigger manager checks for all tailable cursors if
there are new oplog with \texttt{o} object that match the according
query. The cursor is forwarded simultaneously. Thus if
\reffig{lst:oplog} shows the document labeled with 4 or 5 it would be
returned by the query.
\begin{wrapfigure}{r}{0.3\textwidth}
  \centering
  \includegraphics[width=0.3\textwidth]{draw/oplog-cursor}%
  \caption[Tailable cursor on the oplog]{Tailable cursor on the oplog}
  \vspace{-3mm}
  \label{fig:oplog-cursor}
\end{wrapfigure}
\todo[inline]{fix oplog cursor figre}
The trigger manager then calls the callback function and passes the
document from \reffig{lst:oplog}. This way, the application is
notified and can react to the cange with the information contained in
the returned document from the oplog.

\subsection{Unittests}
\label{sec:impl-unittests}
To ensure the quality and correctness of the robot memory, we
implemented unit tests for the important features of this layer. Unit
testing is part of the software development processes test driven
development and extreme programming~\cite{beck-test,beck-xp}. Unit
tests are automated software tests for small units of a program. They
use the functions or components that should be tested and check if the
computed result matches the expected one. Thus they help to locate
bugs, ensure the quality of the unit, and fasten the development
because they can verify if the tests still pass after changes in the
unit. We use unit tests for the robot memory by using the C++
interface of the robot memory and checking if the results are correct
for examples of common use cases. For example there is one test that
checks insert, update, and query operations by inserting a document
into an empty collection, updating it, and querying it by an updated
value. Another test checks if computables work by registering the
computable showed in \reflst{lst:comp-func} and \reflst{lst:comp},
executing the query in \reflst{lst:comp}b and checking if the result
matches \reflst{lst:comp}c. Unittesting in Fawkes is based on Google's
C++ testing framework \emph{gtest}. To test the functionality of the
robot memory in a fully running Fawkes process with dependencies of
the robot memory, such as the \texttt{mongodb} plugin, we integrated
our unit tests into a separate plugin that is started with the robot
memory when the tests are executed.

\section{Application Interface}
\label{sec:impl-planner}
The application interface layer provides the features of the robot
memory for applications such as planners and reasoners. Components
using C++ can directly interface the robot memory layer over its C++
interface. This interface is identical to the interface between the
robot memory and and the interface providers. For example perception
plugins in Fawkes are usually written in C++ and thus can provide
computables or store documents directly in the robot memory. Planner
and reasoner components often utilize specialized languages. For these
components and languages, there are multiple interface providers we
implemented. In the following, we present the interface providers for
PDDL in \refsec{sec:impl-pddl}, for CLIPS in \refsec{sec:impl-clips},
and for OpenRAVE in \refsec{sec:impl-openrave}.

\subsection{PDDL Interface Provider}
\label{sec:impl-pddl}
To find a plan with a PDDL planner, a domain definition and a problem
description need to be provided for the planner. The domain definition
is usually fixed because the predicates defining the world state and
the actions defining the capabilities of the robot often are fixed for
a domain. The problem description, depends on the world model of the
robot and varies in the concrete predicates and the amount of
objects. Thus the problem description depends on the content of the
robot memory and has to be constructed before planning. This process
called \emph{domain creation} is implemented in the
\texttt{pddl-robot-memory} plugin. In \refsec{sec:formalism}, we
theoretically defined the mapping from documents in the robot memory
to PDDL. Nevertheless we need to specify which documents in the robot
memory should be mapped to PDDL and which strings are mapped to which
predicates, functions, and their attributes. These are the $name$
functions. To specify both, we make use of the template engine
\emph{ctemplate}. The template engine takes a \emph{template file} as
input and uses a \emph{dictionary} defined during run-time to exchange
\emph{template markers} in the file by desired string values.
\begin{figure}
  \begin{minipage}{0.58\linewidth}
\begin{lstlisting}[style=SmallPDDL,
  caption={PDDL problem description template},
  label=lst:template,
  framexleftmargin=1pt, xleftmargin=1pt,
 morekeywords={}, numbers=none]
(define (problem blocks_world_generated)
  (:domain blocksworld)
  (:objects A B C D)
  (:goal <<GOAL>>)
  (:init
    <<#ONTABLE|{relation:'on-table'}>>
      (on-table <<object>>) <</ONTABLE>>
    <<#ON|{relation:'on'}>>
      (on <<object_top>> <<object_bottom>>)
    <</ON>>
    <<#HOLDING|{relation:'holding'}>>
      (holding <<object>>) <</HOLDING>>
  ))
\end{lstlisting}
  \end{minipage}
\hfill
  \begin{minipage}{0.42\linewidth}
\begin{lstlisting}[style=SmallPDDL,
  caption={Generated PDDL problem description},
  label=lst:pddl-gen,
  framexleftmargin=1pt, xleftmargin=1pt,
 morekeywords={}, numbers=none]
(define (problem blocks_world_generated)
  (:domain blocksworld)
  (:objects A B C D)
  (:goal (on A B))
  (:init
    (on-table A)
    (on-table C)
    (on D A)
    (holding B)
  ))
\end{lstlisting}
  \end{minipage}
  \vspace{-0.8cm}
\end{figure}
An example template file for the blocks world domain is shown in
\reflst{lst:template}. The result after generating the problem
description based on information in the robot memory is shown in
\reflst{sec:pddl-gen}. A simple template marker is
\texttt{<<GOAL>>}. During the domain creation, the dictionary is
filled with the information that \texttt{<<GOAL>>} should be replaced
by \texttt{(on A B)}. There also are special markers such as
\texttt{<<#ON>> <</ON>>}. They enclose an environment and are called
\emph{list markers} because they insert the enclosed environment for
each list entry of the dictionary on the \texttt{ON} marker. We use
list marker to insert a predicate for each document that is returned
by a query. The query is located in the front marker behind the
\texttt{|} symbol. The enclosed environment can contain markers that
are substituted by key-value paris of documents. In the example given
in \reflst{lst:template}, the query \texttt{\{relation:'on-table'\}}
yields the documents \texttt{\{relation:'on-table', object:'A'\}},
what is mapped to \texttt{(on-table A)}, and
\texttt{\{relation:'on-table', object:'B'\}}, what is mapped to
\texttt{(on-table B)}. To distinguish markers inside these
environments, they are written in lower case.

The process of the domain generation starts with an interface message
containing the goal to the \texttt{pddl-robot-memory} plugin. Then the
plugin parses the problem description template to extract the queries
of the list markers. This is a separate step, because passing
parameters to a list marker is not supported by ctemplate. The plugin
fills the dictionary with the goal and entries for each document
returned by the robot memory for a list marker query. For each such
list entry, all key-value pairs of the documents are inserted into the
dictionary, where the key name in the document equals the marker name
in the template. For sub-documents, the key names are concatinated so
that the marker name is the path to each value. Markers that are not
in the dictionary are later substituted by the empty string. Finally,
the dictionary is passed with the template file to ctemplate, which
generates the resulting problem description.

%mention problem that this template method can not recursively map
%function terms?

The direction back from PDDL to the robot memory is implemented in the
\texttt{pddl-planner} plugin. When the plugin receives an interface
message, it starts the FF planner with the domain and generated
problem description files and waits until the planner finished. Then
the resulting plan is passed, transformed to a document as specified
in the theoretical foundation in \refsec{sec:formalism}, and inserted
into the robot memory. Afterwards an executive can fetch the plan, for
example after being notified by a trigger that there is a new plan.


\color{gray}
\subsection{CLIPS Interface Provider}
\label{sec:impl-clips}
The Interface Provider for CLIPS
can be realized as CLIPS-feature in Fawkes as it was already done for
providing CLIPS access to the blackboard, Protobuf-messaging and the
navgraph. The CLIPS \emph{robot-memory feature} will be implemented in C++
and provides the CLIPS environment with functions that call C++
functions of the robot-memory feature. For example \reflst{lst:clips-rm}
\begin{figure}
  \begin{lstlisting}[showlines,style=ReallySmallCLIPS, caption={CLIPS function to execute a query},
  label=lst:clips-rm,
  emph={skill, args, state, target, res},
  emphstyle=\bfseries\color{green!80!black},
  emph={[2]\?skill, \$\?args, wait-for-lock, \?target, use,
  WAIT-FOR-LOCK, SKILL-EXECUTION, running},
  emphstyle={[2]\bfseries\color{blue!80!black}},
  morekeywords={retract, assert, modify, skill-call, skill-to-execute,
    wait-for-lock}]
(rm-query "database.collection"
          (str-cat "{type:'order', end-time:{$gt:" ?gametime "}}"))
\end{lstlisting} %$ This is just to fix Emacs highlighting due to dollar sign in code above
\end{figure}
would be the CLIPS function, which queries all orders that have not
ended yet, by creating the query using string concatenation to fill in
the current game-time. The result would be a list of pointers to document
objects represented as instances of CLIPS templates. Similarly there
can be functions for registering events and providing computables.

The Domain Creator for CLIPS can be implemented by creating the initial
fact-base with a static list of facts and additional facts resulting
from a set of queries. For example, a domain creator implemented in
the CLIPS language could execute the query function in
\reflst{lst:clips-rm} and assert all orders as facts into the fact
base.
%% possibility to also generate rules form robot memory

CLIPS could use event-triggers to be notified when there is a new PDDL
plan in the robot memory that should be executed or when the world
model has changed in the robot memory and thus facts in CLIPS have to
be updated.


\subsection{OpenRAVE Interface Provider}
\label{sec:impl-openrave}


\section{Application Scenarios}
\label{sec:applicationscenarios}

\subsection{Blocks World with a Robotic Arm}
\label{sec:app-rcll}
\todo[inline]{some images}

\subsection{RoboCup Logistics League}
\label{sec:app-blocks-world}
\todo[inline]{simulation image + real world image}

\color{black}
